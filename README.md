# Red Teaming
Red teaming can be defined as the process of testing your cybersecurity effectiveness through the removal of defender bias by applying an adversarial lens to your organization.


Red teaming occurs when ethical hackers are authorized by your organization to emulate real attackersâ€™ tactics, techniques and procedures (TTPs) against your own systems.

<img src="https://github.com/Mehdi0x90/Coding/assets/17106836/1c6f9e17-1f8e-43f4-81f4-782a05bca923" width="250" height="250">

## Table of Contents
* [Tips and Tricks](https://github.com/Mehdi0x90/Red-Team/blob/main/Tips%20and%20Tricks.md)


## Red Team Scenarios
* [FTP => Path Traversal => CVE](https://github.com/Mehdi0x90/Red-Team/blob/main/FTP%20%3E%20Path%20Traversal%20%3E%20CVE.md)


## Coding & Scripting
* [Bash](https://github.com/Mehdi0x90/Scripts/tree/main/Bash)
* [C/C++](https://github.com/Mehdi0x90/Scripts/tree/main/CPP)
* [Python](https://github.com/Mehdi0x90/Scripts/tree/main/Python)
* [JavaScript](https://github.com/Mehdi0x90/Scripts/tree/main/JavaScript)
* [Powershell](https://github.com/Mehdi0x90/Coding/tree/main/Powershell)
